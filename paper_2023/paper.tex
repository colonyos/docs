\documentclass{article}

\usepackage{arxiv}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{cleveref}       % smart cross-referencing
\usepackage{lipsum}         % Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}
\usepackage{listings}

\title{Colonies - Compute Continuums across Platforms}

\author{{\hspace{1mm}Johan Kristiansson} \\
	Department of Computer Science \\
	RISE Research Institutes of Sweden \\
	Luleå, Sweden \\
	\texttt{johan.kristiansson@ri.se} \\
	\And
	{\hspace{1mm}Thomas Ohlson Timoudas} \\
	Department of Computer Science \\
	RISE Research Institutes of Sweden \\
	Luleå, Sweden \\
	\texttt{thomas.ohlson.timoudas@ri.se} \\
	\And
	{\hspace{1mm}Henrik Forsgren} \\
	Department of Computer Science \\
	RISE Research Institutes of Sweden \\
	Luleå, Sweden \\
	\texttt{thomas.ohlson.timoudas@ri.se} \\
}

% Uncomment to override  the `A preprint' in the header
%\renewcommand{\headeright}{Technical Report}
%\renewcommand{\undertitle}{Technical Report}
\renewcommand{\shorttitle}{\textit{arXiv} Template}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={A template for the arxiv style},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={David S.~Hippocampus, Elias D.~Striatum},
pdfkeywords={First keyword, Second keyword, More},
}

\begin{document}
\maketitle

\begin{abstract}
Running AI/ML models in production is becoming widespread. At the same time, developing and maintaining AI workloads are becoming more difficult. In particular, most workloads are not portable and cannot easily be moved from one provider to another. Creating and operating fully automated end-to-end workflows across devices, edge, cloud adds even more complexity.

This paper presents a novel framework for running computational workload across heterogeneous platforms. Colonies is based on a loosely coupled microservice architecture where complex workflows are broken down in composable functions that are executed by independently deployable executors. Using a HTTP protocol, functions can be composed into declarative workflows in any computer language. The workflows are then executed across platforms by independently deployed executors running in the cloud, edge, devices, or even in web browser, creating compute continuums across platforms. Colonies support both real-time processing and batch jobs while at the same time offer full traceability and zero-trust security.

The paper also describes how Colonies can be used to build a scalable remote sensing platform on Kubernetes, how it can be used as a building block for edge computing, and how it can be integrated with HPC platforms. Finally, the paper presents a performance investigation as well as a scalability and robustness evaluation. 
\end{abstract}

% keywords can be removed
\keywords{Serverless computing \and Parallel computing \and Workflow orchestration}

\section{Introduction}
Building robust and scalable AI systems is challenging and requires deep understanding in various fields. First an AI model must be trained, requiring technical skills in advanced statistics or machine learning, but also access to training and validation data. Usually, the data need to be pre-processed in several steps before it can be used, or a simulator needs to be developed to either generate syntentic data or play back historical data. While it may be resonable for small scale projects to run a whole environment on a local development computer, training large AI models usually requires access to powerful compute clusters or even HPC systems. Manually utilizing such infrastructure is cumbersome and time consuming. Being able to automate the training processes makes it possible to more quickly iterate and find useful models.  

Going forward and taking an AI model into production requires significant software engineering skills. In constract to traditional IT workloads both the data and the model itself need to be managed. As most models need to be re-trained or re-calibrated regularly, it muste be possible to seamlessly update deployed model and the software without loosing information or introducing delays. In many cases, there is a constant flow of data that is ingested into the system that needs to be managed while parts of the system is not working correctly. This becomes even more challenging when nodes parts of the underlying infrastructure crashes or becomes unavailable due to maintenance such as software updates or misconfiguration errors. 

Sometimes there is also need to scale the system to increase capacity or scale down to save resources. This is particularly important when using expensive cloud resources. Scaling the system means that underlying infastructure may change anytime causing additional failures. It must therefor be possible to detected failed computations and re-process failed tasks part of a larger workflow. If failed computation cannot gracefully be recovered, there must be a away for engineers perform root cause analysis and manually recover failures. 










Taking an AI model intro production, 

Development
 - Data science
 - Production system
 - Integration, data ingestion, pre-processing
 Workflows, real-time processing, back processing.
Operation
 - Computer faults
 - Updates, DevOps
Scability
HPC
 Requires a whole different set of toolchains. 

 


https://modelserving.com/blog/why-do-people-say-its-so-hard-to-deploy-a-ml-model-to-production
\section{The Colonies framework}
\label{sec:headings}

\subsection{Architecture}
TODO
\begin{figure}[h]
	\centering
    \includegraphics[scale=0.4]{arch.png}
	\caption{cron management}
	\label{fig:fig1}
\end{figure}

\begin{figure}[h]
	\centering
    \includegraphics[scale=0.4]{raft.png}
	\caption{cron management}
	\label{fig:fig1}
\end{figure}

\subsubsection{Workflows}
TODO
\begin{figure}[h]
	\centering
    \includegraphics[scale=0.32]{workflow.png}
	\caption{cron management}
	\label{fig:fig1}
\end{figure}

\begin{table}[h]
	\caption{Function Specifications}
	\centering
	\begin{tabular}{llllll}
		\toprule
		\cmidrule(r){1-2}
        Function Spec & Function        & Executor Type & Priority & Max Exec Time & Max Retries \\
		\midrule
        $F_{1}$       & gen\_nums()     & Edge          & 1        & 200 s         & 5 \\
        $F_{2}$       & square()        & Cloud         & 1        & 200 s         & 5 \\
        $F_{3}$       & square()        & Cloud         & 1        & 200 s         & 5 \\
        $F_{4}$       & sum()           & Browser       & 1        & 200 s         & 5 \\
		\bottomrule
	\end{tabular}
	\label{tab:table}
\end{table}

\begin{table}[h]
	\caption{Snapshot of Process Table as in Step 2}
	\centering
	\begin{tabular}{llllll}
		\toprule
		\cmidrule(r){1-2}
        Process Id & Function Spec & Wait for Parents & Assigned Executor Id & State      & Priority Time \\
		\midrule
        $P_{1}$    & $F_{1}$       & $False$          & $E_{1}$              & Successful & 1679906715352024000 \\
        $P_{2}$    & $F_{2}$       & $False$          & $E_{1}$              & Running    & 1679906715353453000 \\
        $P_{3}$    & $F_{3}$       & $False$          & $E_{2}$              & Running    & 1679906715354286000 \\
        $P_{4}$    & $F_{4}$       & $True$           & -                    & Waiting    & 1679906715355188000 \\
		\bottomrule
	\end{tabular}
	\label{tab:table}
\end{table}

dt = -1000000000 * 60 * 60 * 24
process.PriorityTime = int64(process.FunctionSpec.Priority)*dt + submissionTime.UnixNano()


\begin{table}[h]
	\caption{Dependency Table}
	\centering
	\begin{tabular}{lll}
		\toprule
		\cmidrule(r){1-2}
        Process Id & Name       & Dependencies           \\
		\midrule
        $P_{1}$    & $Task_{1}$ & -                      \\
        $P_{2}$    & $Task_{2}$ & $Task_{1}$             \\
        $P_{3}$    & $Task_{3}$ & $Task_{1}$             \\
        $P_{4}$    & $Task_{4}$ & $Task_{2}$, $Task_{3}$ \\
		\bottomrule
	\end{tabular}
	\label{tab:table}
\end{table}
	
\begin{table}[h]
	\caption{Input/Output Table}
	\centering
	\begin{tabular}{lll}
		\toprule
		\cmidrule(r){1-2}
        Process Id & Input & Output \\
		\midrule
        $P_{1}$    & & [2,3] \\
        $P_{2}$    & 2 & 4 \\
        $P_{3}$    & 3 & 9 \\
        $P_{4}$    & [4,9] & 13 \\
		\bottomrule
	\end{tabular}
	\label{tab:table}
\end{table}

\subsubsection{Cron}
TODO
\begin{figure}[h]
	\centering
    \includegraphics[scale=0.4]{cron.png}
	\caption{Sample figure caption.}
	\label{fig:fig1}
\end{figure}

\subsubsection{Generators}
TODO

\subsubsection{Zero-trust security}
TODO

\section{Evaluation}
\subsection{Implementation}
\begin{lstlisting}[language=c]
gen_nums = Function(gen_data, colonyid, executortype="edge")
square1 = Function(square, colonyid, executortype="cloud")
square2 = Function(square, colonyid, executortype="cloud")
sum = Function(square, colonyid, executortype="browser")

wf = ColoniesWorkflow("localhost", 50080, colonyid, executor_prvkey)
wf >> gennums
gennums >> square1
gennums >> square2
[square1, square2] >> sum
res = wf.execute()
\end{lstlisting}

\subsection{References}
TODO
\bibliographystyle{unsrtnat}
\bibliography{references}  %%% Uncomment this line and comment out the ``thebibliography'' section below to use the external .bib file (using bibtex) .


%%% Uncomment this section and comment out the \bibliography{references} line above to use inline references.
% \begin{thebibliography}{1}

% 	\bibitem{kour2014real}
% 	George Kour and Raid Saabne.
% 	\newblock Real-time segmentation of on-line handwritten arabic script.
% 	\newblock In {\em Frontiers in Handwriting Recognition (ICFHR), 2014 14th
% 			International Conference on}, pages 417--422. IEEE, 2014.

% 	\bibitem{kour2014fast}
% 	George Kour and Raid Saabne.
% 	\newblock Fast classification of handwritten on-line arabic characters.
% 	\newblock In {\em Soft Computing and Pattern Recognition (SoCPaR), 2014 6th
% 			International Conference of}, pages 312--318. IEEE, 2014.

% 	\bibitem{hadash2018estimate}
% 	Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and Alon
% 	Jacovi.
% 	\newblock Estimate and replace: A novel approach to integrating deep neural
% 	networks with existing applications.
% 	\newblock {\em arXiv preprint arXiv:1804.09028}, 2018.

% \end{thebibliography}

\end{document}
